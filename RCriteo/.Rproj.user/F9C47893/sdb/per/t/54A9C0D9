{
    "contents" : "################################################################################\n##################### Kaggle Criteo Challenge ##################################\n################################################################################\n## clear data\nrm(list = ls())\ncat(\"\\014\")\n\ncols_to_keep<-c(6,9,14,17,20,22,23)\nntrain<-1000\nntest<-6042136\nblockCount<-10000\ntrainFile<-\"/home/harini/Kaggle_data/Criteo/train_reduced.csv\"\n#trainSQLFile<-\"/home/harini/Kaggle_data/Criteo/train_db_sql\"\n#trainFile<-\"../../../../Kaggle_CriteoChallenge/train.csv\"\ntestFile<-\"/home/harini/Kaggle_data/Criteo/test.csv\"\n#testSQLFile<-\"/home/harini/Kaggle_data/Criteo/test_db_sql\"\n#testFile<-\"../../../../Kaggle_CriteoChallenge/temp.csv\"\noutFile<-\"criteo_submission_log_07252014.csv\"\n\n##load packages\nlibrary(randomForest) \nlibrary(sqldf)\n\nMode <- function(x) {\n  ux <- unique(x)\n  ux <- setdiff(ux,NA)\n  max_val = ux[which.max(tabulate(match(x, ux)))]\n  x[is.na(x)]<-max_val\n  list(mode_val=max_val,unique_val=ux,data=x)\n}\n\nprocess_data <- function(data){\n  keeps <- c(paste(\"I\",sep=\"\",c(1:13)),paste(\"C\", sep=\"\", cols_to_keep))\n  data <- data[,(names(data) %in% keeps)]\n  int_cols <- c(paste(\"I\",sep=\"\",c(1:13)))\n  for (i in int_cols){\n    data[,i] <-  as.integer(data[,i])  \n  }\n  factor_cols <- c(paste(\"C\", sep=\"\", cols_to_keep))\n  for (i in factor_cols){\n    data[,i] <-  as.factor(data[,i])  \n  }  \n  temp<-sapply(data, Mode)\n  max_val <- temp[1,]\n  unique_val <- temp[2,]\n  data[,1:ncol(data)]<- temp[3,] \n  list(data=data,max_val=max_val,unique_val=unique_val)\n}\n\nprocess_data_test <- function(data,max_val,unique_val){\n  keeps <- c(paste(\"I\",sep=\"\",c(1:13)),paste(\"C\", sep=\"\", cols_to_keep))\n  data <- data[,(names(data) %in% keeps)]\n  int_cols <- c(paste(\"I\",sep=\"\",c(1:13)))\n  for (i in int_cols){\n    data[,i] <-  as.integer(data[,i])  \n  }\n  factor_cols <- c(paste(\"C\", sep=\"\", cols_to_keep))\n  for (i in factor_cols){\n    data[,i] <-  as.factor(data[,i])  \n  } \n  for (i in colnames(data)){\n    if(is.factor(data[,i])){\n      data[,i]<-factor(data[,i],levels=unique_val[[i]])\n    }\n    data[is.na(data[i]),i]<-max_val[[i]]\n    id <- which(!(data[,i] %in% unique_val[[i]]))\n    if(!(length(id)==0)){data[id,i]<- max_val[[i]]}\n  }\n  data\n}\n\n## read train data base if doesnt exist\nif (file.exists(trainSQLFile)) {\n  sprintf(\"File exists\\n\")\n}else{\n  sqldf(paste(\"attach '\",trainSQLFile,\"' as new\",sep=\"\"))\n  read.csv.sql(trainFile, sql = \"create table train as select * from file\", dbname = trainSQLFile)\n}\n\n#read some training data\ns <- sprintf(\"select * from main.train limit %d, %d\", 0, ntrain) \ndata<-sqldf(s, dbname = trainSQLFile)\ny <- as.factor(data[,\"Label\"])\ntemp<-process_data(data)\nmax_val <- temp$max_val\nunique_val <- temp$unique_val\ndata<- temp$data\nrm(temp)\n\n## run Random Forest\nev <- c(paste(\"I\",sep=\"\",c(1:13)),paste(\"C\", sep=\"\", cols_to_keep))\nmylogit <- glm(y ~ ev, data = mydata, family = \"binomial\")\nrm(data)\n\n## read test database if it doesnt exist\nif (file.exists(testSQLFile)) {\n  sprintf(\"File exists\\n\")\n}else{\n  sqldf(paste(\"attach '\",testSQLFile,\"' as new\",sep=\"\"))\n  read.csv.sql(testFile, sql = \"create table main.test as select * from file\", dbname = testSQLFile)\n}\n\n#read test data in chunks and predict\nitem_ids <- c()\npredictions <- c()\nfor(i in seq(0, ntest, blockCount)) { \n  s <- sprintf(\"select * from main.test limit %d, %d\", i, blockCount) \n  data<-sqldf(s, dbname = testSQLFile)\n  item_ids<-rbind(item_ids,data[\"Id\"])\n  data <- process_data_test(data,max_val,unique_val)\n  \n  temp<-predict(mylogit, newdata = data, type = \"response\")\n  predictions<-cbind(predictions,t(temp[,2]))\n  \n  #write output into submission file\n  outdata<-data.frame(item_ids,t(predictions))\n  colnames(outdata)<-c(\"Id\",\"Predicted\")\n  if(i==0){\n    write.table(outdata, file = outFile,sep=\",\", row.names=FALSE,col.names=TRUE,append = TRUE)\n  }else{\n    write.table(outdata, file = outFile,sep=\",\", row.names=FALSE,col.names=FALSE,append = TRUE)\n  }\n  temp<-c()\n  item_ids <- c()\n  predictions <- c()\n  print(i)\n} \n\n",
    "created" : 1406656032486.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2664340684",
    "id" : "54A9C0D9",
    "lastKnownWriteTime" : 1406656107,
    "path" : "~/Dropbox/kaggle/Criteo/RCriteo/RunLogisticRegression_sql.R",
    "project_path" : "RunLogisticRegression_sql.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}